# -*- coding: utf-8 -*-
"""own-sa-impl-draft1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qoMk4a18SwWErDuE5orF4LlCXr5gvV7V
"""

'''Please pip3 install adapt before running this file'''

import warnings
warnings.filterwarnings("ignore")

# import statements
import numpy as np
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import LabelEncoder
from sklearn.decomposition import PCA

import adapt
from adapt.feature_based import SA

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC, LinearSVC
from sklearn.neural_network import MLPClassifier
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier

class OwnSubspaceAlignment:
    def __init__(self, estimator, n_components):
    	# n_components: feature dimension after PCA
        self.estimator = estimator
        self.n_components = n_components
        self.sign_mtx = np.array([[1,0],[0,1]])
    
    def fit(self, Xs, Ys, Xt, Xtl=None, Ytl=None):
    	# training of SA
    	# Xs: source domain feature matrix, [Ns, D_feat]
    	# Ys: labels in source domain
    	# Xt: target domain feature matrix, [Nt, D_feat]
    	# Xtl, Ytl: labeled target data. Do sign flipping if they are not None.

        self.pca_src_ = PCA(self.n_components)
        self.pca_src_.fit(Xs)
        self.pca_tgt_ = PCA(self.n_components)
        self.pca_tgt_.fit(Xt)

        self.M_  = self.pca_src_.components_ @ self.pca_tgt_.components_.T
        
        Xs_tf = self.transform(Xs, domain="src")
        self.estimator.fit(Xs_tf, Ys)
        
        if Xtl is not None and Ytl is not None:
            besti, bestj = 1, 1
            bestacc = 0
            for i in (1,-1):
                for j in (1,-1):
                    self.sign_mtx = np.array([[i,0],[0,j]])
                    acc = self.score(Xtl, Ytl)
                    if acc>bestacc:
                        bestacc, besti, bestj = acc, i, j
            self.sign_mtx = np.array([[besti,0],[0,bestj]])
        return
    
    def score(self, X, y):
    	# test trained SA on testing set X and y
    	# return the testing accuracy, value in [0,1]
        X_tf = self.transform(X, domain="tgt")
        if hasattr(self.estimator, "score"):
            score = self.estimator.score(X_tf, y)
        elif hasattr(self.estimator, "evaluate"):
            if np.prod(X.shape) <= 10**8:
                score = self.estimator.evaluate(X_tf, y, batch_size=len(X))
            else:
                score = self.estimator.evaluate(X_tf, y)
            if isinstance(score, (tuple, list)):
                score = score[0]
        else:
            raise ValueError("Estimator does not implement score or evaluate method")
        return score
    
    def transform(self, X, domain="tgt"):
        if domain in ["tgt"]:
            return self.pca_tgt_.transform(X) @ self.sign_mtx
        elif domain in ["src"]:
            return self.pca_src_.transform(X) @ self.M_
        else:
            raise ValueError("`domain `argument should be `tgt` or `src`, got, %s"%domain)

def get_clf(Q,k=31):
    # get classifier based on input value below
    if Q==1:
        clf = MLPClassifier(random_state=1, max_iter=300)
    elif Q==2:
        clf = KNeighborsClassifier(n_neighbors=k)
    elif Q==3:
        clf = LinearSVC(random_state=0, tol=1e-5)
    elif Q==4:
        clf = SVC(random_state=0, tol=1e-5)
    elif Q==5:
        clf = GaussianProcessClassifier(random_state=1)
    elif Q==6:
        clf = DecisionTreeClassifier(random_state=0)
    elif Q==7:
        clf = RandomForestClassifier(max_depth=2, random_state=0)
    elif Q==8:
        clf = LinearDiscriminantAnalysis()
    elif Q==9:
        clf = AdaBoostClassifier(n_estimators=100, random_state=0)
    else:
        clf = None
        print(f'Non-implemented clf {Q}')
    return clf

def experiment(Xs, Ys, Xt, Yt, Xtest, Ytest, Q=1, k=31):
	# return SA testing acc and SL testing acc, under the setting specified in arguments.
	# Q: name of classifier, str
	# k: number of neighbors for KNN

    '''np.random.seed(2022)'''
    # notations: score_SA (testing accuracy of SA, in [0,1])
    est = get_clf(Q, k)

    model = OwnSubspaceAlignment(est, n_components=2)
    model.fit(Xs, Ys, Xt)
    score_SA = model.score(Xtest, Ytest)
    
    # notations: score_SL (testing accuracy of SL, in [0,1])
    est = get_clf(Q, k)

    est.fit(Xs, Ys)
    score_SL = est.score(Xtest, Ytest)
    
    print(f'score_SA {score_SA}, score_SL {score_SL}')
    return score_SA, score_SL

def execute():
    # data processing and assigning to source and target
    datafile = 'flare.dat'
    df = pd.read_csv(datafile, sep="\s+", header=None)

    cat = pd.DataFrame()
    cat[0] = df[0]
    cat[1] = df[1]
    cat[2] = df[11]
    df = df.drop([0,1,11], axis=1)

    cat = cat.apply(LabelEncoder().fit_transform)
    df[0], df[1], classes = cat[0], cat[1], cat[2]

    for i in range(2,11):
        df[i] = df[i].str.replace(',', '').astype(int)

    model = KMeans(n_clusters=2)
    model.fit(df)
    y_pred = pd.DataFrame(model.predict(df))

    df['y_pred'] = y_pred

    Xt = df[df['y_pred'] == 0]
    Yt = classes[df['y_pred']==0]
    Xs = df[df['y_pred'] == 1]
    Ys = classes[df['y_pred'] == 1]

    split = int(len(Xt)/2)
    Xtest = Xt[split:]
    Ytest = Yt[split:]
    Xt = Xt[:split]
    Yt = Yt[:split]

    est = int(input('''
        Which estimator/base classifier would you like to run Subspace Alignment on?
        Enter as follows:
        1 for MLP
        2 for K Neighbors
        3 for Linear SVC
        4 for SVC
        5 for Gaussian Process
        6 for Decision Tree
        7 for Random Forest
        8 for Linear Discriminant Analysis
        9 for AdaBoost
        '''))
    
    sa, sl = experiment(Xs=Xs, Ys=Ys, Xt=Xt, Yt=Yt, Xtest=Xtest, Ytest=Ytest, Q=est)

    est = get_clf(est)
    model = SA(est, Xt=Xt, random_state=0)
    model.fit(Xs, Ys)
    score = model.score(Xt, Yt)

    return f'Own implementation score: {sa}, Adapt implementation score: {score}'